import numpy as np
import pandas as pd

import os
import argparse
from configparser import ConfigParser
from ..utils.file_handlers import get_dataset, index_from_dataset, save_df_to_pickle
from ..utils.core_periphery import get_core_periphery_structure

# ArgParser
parser = argparse.ArgumentParser(description = "Create similarity dataset")
parser.add_argument("--config", "-c", type = str, help = "path/to/config.ini", required=True)
args = parser.parse_args()
config_path = args.config

# Reading settings
config = ConfigParser()
config.read(config_path)

dataset_path = config.get('dataset', 'dataset_path')
nodes_classification_df_path = config.get('core and periphery', 'nodes_classification_df_path')
gen_vul_df_path = config.get('core and periphery', 'gen_vul_df_path')

# Reading data
G_dataset = get_dataset(dataset_path, verbose = False)
nodes_classification_df = pd.read_pickle(nodes_classification_df_path)

# Filter living nodes
nodes_classification_df = nodes_classification_df[nodes_classification_df['ECO'] == 1]

# Collect generality and vulnerability for each node
rows = []
for G in G_dataset:
    L_S = G.ecount() / G.vcount()
    for periphery_structure_name, node_set in get_core_periphery_structure(G).items():
        for node_id in node_set:
            v = G.vs()[node_id]
            if v['ECO'] == 1.0:
                vul = 1 / L_S * v.outdegree()
                gen = 1 / L_S * v.indegree()
            else:
                vul = None
                gen = None
            row = [G['name'], node_id, v['name'], v['ECO'], v['trophic_level'], periphery_structure_name, gen, vul]
            rows.append(row)
node_periphery_gen_vul_df = pd.DataFrame(rows, columns = ['Network', 'node_id', 'name', 'ECO', 'trophic level', 'structure', 'generality', 'vulnerability'])

columns = ['Network', 'Node ID', 'Node Name', 'ECO', 'Trophic Level', 'Structure', 'Generality', 'Vulnerability']
gen_vul_df = pd.DataFrame(rows, columns = columns)
save_df_to_pickle(gen_vul_df, gen_vul_df_path)

